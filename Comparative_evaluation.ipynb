{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparative_evaluation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZbIaMkBvQwXeCfcVPLj3a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larrygoyeau/bubble_segmentation_Mask_RCNN/blob/master/Comparative_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an6exxwqjhFv",
        "colab_type": "text"
      },
      "source": [
        "This notebook, present a comparative analyses between Unet and Mask RCNN by computing the IOU and mAP scores and the time of execution on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6064e73e-6a5d-401a-961f-e9655dba9e01",
        "cellView": "form",
        "id": "JWuXCaminMrn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "#@title To load Unet, run this block.\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "!git clone https://github.com/larrygoyeau/bubble_segmentation_Unet\n",
        "\n",
        "# Install required libs\n",
        "import os\n",
        "os.system('pip install albumentations==0.4.5')\n",
        "os.system('pip install -U efficientnet==1.0.0')\n",
        "os.system('pip install image-classifiers==1.0.0')\n",
        "os.system('pip install -U segmentation-models==1.0.0')\n",
        "\n",
        "import sys\n",
        "import random\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import keras\n",
        "from keras.models import model_from_json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "import segmentation_models as sm\n",
        "import resource\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "    \n",
        "# helper function for data visualization    \n",
        "def denormalize(x):\n",
        "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
        "    x_max = np.percentile(x, 98)\n",
        "    x_min = np.percentile(x, 2)    \n",
        "    x = (x - x_min) / (x_max - x_min)\n",
        "    x = x.clip(0, 1)\n",
        "    return x\n",
        "    \n",
        "\n",
        "# classes for data loading and preprocessing\n",
        "class Dataset:\n",
        "    \n",
        "    def __init__(\n",
        "            self, \n",
        "            images_dir=None,\n",
        "            preprocessing=None,\n",
        "            augmentation=None,\n",
        "    ):\n",
        "        self.ids_image = os.listdir(images_dir)\n",
        "        \n",
        "        if images_dir!=None:\n",
        "          self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids_image]\n",
        "        else:\n",
        "          self.images_fps=None\n",
        "   \n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "        self.augmentation=augmentation\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # read data\n",
        "        if self.images_fps!=None:\n",
        "          image = cv2.imread(self.images_fps[i])\n",
        "        else:\n",
        "          image = self.image\n",
        "        if len(image)>2**11:\n",
        "          image=image[:2**11,:]\n",
        "        if len(image[0])>2**11:\n",
        "          image=image[:,:2**11]\n",
        "        shape_image=image.shape\n",
        "        p=255/(image.max()-image.min())\n",
        "        image=(image-image.min())*p\n",
        "        image= image.astype(np.uint8)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.augmentation:\n",
        "          I=len(image)\n",
        "          J=len(image[0])\n",
        "          sample = self.augmentation(I,J)(image=image)\n",
        "          image = sample['image']\n",
        "        \n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image)\n",
        "            image= sample['image']\n",
        "            \n",
        "        return image, shape_image\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.ids_image)\n",
        "\n",
        "def round_clip_0_1(x, **kwargs):\n",
        "    return x.round().clip(0, 1)\n",
        "\n",
        "\n",
        "def get_validation_augmentation(I,J):\n",
        "    \"\"\"Add paddings\"\"\"\n",
        "    if I>384 or J>544:\n",
        "      test_transform = [A.PadIfNeeded(2**(int(np.log(I-1)/np.log(2))+1), 2**(int(np.log(J-1)/np.log(2))+1), border_mode=0)]\n",
        "    else:\n",
        "      test_transform = [A.PadIfNeeded(384, 544, border_mode=0)]\n",
        "    return A.Compose(test_transform)\n",
        "\n",
        "def get_preprocessing(preprocessing_fn):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "    \n",
        "    Args:\n",
        "        preprocessing_fn (callbale): data normalization function \n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    _transform = [\n",
        "        A.Lambda(image=preprocessing_fn),\n",
        "    ]\n",
        "    return A.Compose(_transform)\n",
        "\n",
        "BACKBONE = 'efficientnetb3'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "LR = 0.0001\n",
        "\n",
        "# define network parameters\n",
        "n_classes =3 # case for binary and multiclass segmentation\n",
        "activation = 'softmax'\n",
        "\n",
        "# define optimizer\n",
        "optim = keras.optimizers.Adam(LR)\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1-1ot0U_PFeSs9pdpIbd3RoTOrxrOzxnb',\n",
        "                                    dest_path='/content/model_Unet.json',\n",
        "                                    unzip=False)\n",
        "json_file = open('/content/model_Unet.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model_Unet = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model, you can change the path if you don't use colab\n",
        "MODEL_PATH = '/content/model_Unet.h5'\n",
        "gdd.download_file_from_google_drive(file_id='1fGFApwvmk64gmpmyEm_GNYb-YEP3fSt4',\n",
        "                                    dest_path=MODEL_PATH,\n",
        "                                    unzip=False)\n",
        "\n",
        "model_Unet.load_weights(MODEL_PATH)\n",
        "\n",
        "# compile keras model with defined optimozer, loss and metrics\n",
        "model_Unet.compile(optim,loss='categorical_crossentropy')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'bubble_segmentation_Unet'...\n",
            "remote: Enumerating objects: 117, done.\u001b[K\n",
            "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 1051 (delta 66), reused 0 (delta 0), pack-reused 934\u001b[K\n",
            "Receiving objects: 100% (1051/1051), 340.72 MiB | 12.33 MiB/s, done.\n",
            "Resolving deltas: 100% (640/640), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading 1-1ot0U_PFeSs9pdpIbd3RoTOrxrOzxnb into /content/model_Unet.json... Done.\n",
            "Downloading 1fGFApwvmk64gmpmyEm_GNYb-YEP3fSt4 into /content/model_Unet.h5... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "1y0DIyx6nTA8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "264020cc-2402-4c08-df1e-01adec6688df"
      },
      "source": [
        "#@title To load Mask RCNN, run this block. { run: \"auto\" }\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import os\n",
        "os.system('git clone https://github.com/larrygoyeau/Mask_RCNN')\n",
        "os.system('pip install -r /content/Mask_RCNN/requirements.txt')\n",
        "os.system('git clone https://github.com/larrygoyeau/bubble_segmentation_Mask_RCNN')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/Mask_RCNN')\n",
        "\n",
        "import resource\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from skimage.measure import find_contours\n",
        "from matplotlib.patches import Polygon\n",
        "import requests\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"/content\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "from mrcnn.config import Config\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn import utils\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# To increas the recursion limite\n",
        "resource.setrlimit(resource.RLIMIT_STACK, [0x100000000, resource.RLIM_INFINITY])\n",
        "sys.setrecursionlimit(0x1000000)\n",
        "\n",
        "def get_ax(rows=1, cols=1, size=8):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Change the default size attribute to control the size\n",
        "    of rendered images\n",
        "    \"\"\"\n",
        "    #fif, ax = plt.subplots(rows, cols, figsize=(size*1.5, size*rows))\n",
        "    return plt.subplots(rows, cols, figsize=(size*1.5, size*rows))\n",
        "\n",
        "class InferenceConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy shapes dataset.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the toy shapes dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"shapes\"\n",
        "\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    IMAGE_RESIZE_MODE = \"pad64\"\n",
        "    RPN_NMS_THRESHOLD = 0.55\n",
        "    DETECTION_MAX_INSTANCES=350\n",
        "    MAX_GT_INSTANCES=350\n",
        "    DETECTION_MIN_CONFIDENCE=0\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # background + 1 shape\n",
        "\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "\n",
        "\n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# To increas the recursion limite\n",
        "resource.setrlimit(resource.RLIMIT_STACK, [0x100000000, resource.RLIM_INFINITY])\n",
        "sys.setrecursionlimit(0x1000000)\n",
        "\n",
        "DATA_DIR = '/content/bubble_segmentation_Mask_RCNN/data_set'\n",
        "\n",
        "x_test_dir = os.path.join(DATA_DIR, 'image_test')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'interior_mask_test')\n",
        "\n",
        "#Some utility functions:\n",
        "\n",
        "def color_bubble(mask_of_one_bubble,mask,i,j,I,J,color_of_bubble_done,color_of_bubbles_to_be_done):\n",
        "  if mask[i,j]<color_of_bubbles_to_be_done:\n",
        "    mask[i,j]=color_of_bubble_done\n",
        "    mask_of_one_bubble[i,j]=1\n",
        "    if 0<j:\n",
        "      color_bubble(mask_of_one_bubble,mask,i,j-1,I,J,color_of_bubble_done,color_of_bubbles_to_be_done)\n",
        "    if i<I-1:\n",
        "      color_bubble(mask_of_one_bubble,mask,i+1,j,I,J,color_of_bubble_done,color_of_bubbles_to_be_done)\n",
        "    if 0<i:\n",
        "      color_bubble(mask_of_one_bubble,mask,i-1,j,I,J,color_of_bubble_done,color_of_bubbles_to_be_done)\n",
        "    if j<J-1:\n",
        "      color_bubble(mask_of_one_bubble,mask,i,j+1,I,J,color_of_bubble_done,color_of_bubbles_to_be_done)\n",
        "\n",
        "class ShapesDataset(utils.Dataset):\n",
        "\n",
        "\n",
        "    def load_shapes(self,images_dir, masks_dir):\n",
        "\n",
        "        # Add classes\n",
        "        self.add_class(\"shapes\", 1, \"bubble\")\n",
        "\n",
        "        # Add images\n",
        "        self.ids_image = os.listdir(images_dir)\n",
        "        \n",
        "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids_image]\n",
        "        if masks_dir!=None:\n",
        "          self.masks_fps = [os.path.join(masks_dir,'mask'+image_id[5:]) for image_id in self.ids_image]\n",
        "        else:\n",
        "          self.masks_fps=None\n",
        "\n",
        "        count=len(self.ids_image)\n",
        "        \n",
        "        for i in range(count):\n",
        "            self.add_image(\"shapes\", image_id=i, path=self.images_fps[i],path_mask=self.masks_fps[i])\n",
        "\n",
        "    def load_image(self, image_id):\n",
        "        \"\"\"Generate an image from the specs of the given image ID.\n",
        "        This function loads the image from a file\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        image = cv2.imread(info['path'])\n",
        "        if len(image)>2**11:\n",
        "          image=image[:2**11,:]\n",
        "        if len(image[0])>2**11:\n",
        "          image=image[:,:2**11]\n",
        "        shape_image=image.shape\n",
        "        p=255/(image.max()-image.min())\n",
        "        image=(image-image.min())*p\n",
        "        image= image.astype(np.uint8)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        return image\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"The annotations are the same as those used for Unet \n",
        "        except that this function allows you to create, \n",
        "        from a mask containing all the bubbles,\n",
        "         a set of mask, each containing a bubble so that the annotation is indeed of the type \n",
        "         'instance' and not 'semantic'.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        mask = cv2.imread(info['path_mask'], 0)\n",
        "        I=len(mask)\n",
        "        J=len(mask[0])\n",
        "        number_of_bubbles=0\n",
        "        list_of_mask=[]\n",
        "        for i in range(I):\n",
        "          for j in range(J):\n",
        "            if mask[i,j]<5:\n",
        "              mask_of_one_bubble=np.zeros( mask.shape, dtype=np.int32 )\n",
        "              color_bubble(mask_of_one_bubble,mask,i,j,I,J,255,5)\n",
        "              list_of_mask=list_of_mask+[mask_of_one_bubble]\n",
        "              number_of_bubbles=number_of_bubbles+1\n",
        "        list_of_mask=np.random.permutation(list_of_mask)\n",
        "        mask_of_all_bubbles = np.stack(list_of_mask, axis=-1).astype('int')\n",
        "        class_ids = np.ones((number_of_bubbles))\n",
        "        return mask_of_all_bubbles.astype(np.bool), class_ids.astype(np.int32)\n",
        "\n",
        "def semantic_mask(instance_mask):\n",
        "  N=len(instance_mask[0][0])\n",
        "  I=len(instance_mask)\n",
        "  J=len(instance_mask[0])\n",
        "  mask=np.zeros(instance_mask[...,0].shape)\n",
        "  for n in range(N):\n",
        "    for i in range(I):\n",
        "      for j in range(J):\n",
        "        if instance_mask[i,j,n]:\n",
        "          mask[i,j]=1\n",
        "  return mask\n",
        "\n",
        "# Test dataset\n",
        "dataset_test = ShapesDataset()\n",
        "dataset_test.load_shapes(x_test_dir, y_test_dir)\n",
        "dataset_test.prepare()\n",
        "\n",
        "# Download trained weights from Releases if needed\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "MODEL_PATH = '/content/model.h5'\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    file_id = '16m6o97REebp_C86IbjbaHitxUvjBjrBe'\n",
        "    destination = MODEL_PATH\n",
        "    download_file_from_google_drive(file_id, destination)\n",
        "    print(\"Pretrained model downloaded!\")\n",
        "\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model_Mask_RCNN = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=ROOT_DIR)\n",
        "\n",
        "# Load trained weights\n",
        "model_Mask_RCNN.load_weights(MODEL_PATH, by_name=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pretrained model downloaded!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:758: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:760: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On_QYNpXcYek",
        "colab_type": "text"
      },
      "source": [
        "To compute mAP the predicted mask must be of instance type. As Unet give a semantic mask, we will save it and then use the function load_mask to get intance masks prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "195830f8-20f4-4771-fb90-736636abeb6d",
        "id": "oFUBg_IrndNK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "if not os.path.exists('/content/pr_dir'):\n",
        "  base_dir = 'pr_dir'\n",
        "  os.mkdir(base_dir)\n",
        "\n",
        "test_dataset = Dataset(\n",
        "    x_test_dir, \n",
        "    preprocessing=get_preprocessing(preprocess_input),\n",
        "    augmentation=get_validation_augmentation\n",
        ")\n",
        "\n",
        "image_names=os.listdir(x_test_dir)\n",
        "n =len(image_names)\n",
        "average_iou_Unet=0\n",
        "\n",
        "for k in range(n):\n",
        "    image, shape_image= test_dataset[k]\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    pr_mask = model_Unet.predict(image).round()[0]\n",
        "\n",
        "    image=image[0]\n",
        "    image=image[int((len(image)-shape_image[0])/2):int((len(image)-shape_image[0])/2)+shape_image[0]]\n",
        "    image=image[:,int((len(image[0])-shape_image[1])/2):int((len(image[0])-shape_image[1])/2)+shape_image[1]]\n",
        "    pr_mask=pr_mask[int((len(pr_mask)-shape_image[0])/2):int((len(pr_mask)-shape_image[0])/2)+shape_image[0]]\n",
        "    pr_mask=pr_mask[:,int((len(pr_mask[0])-shape_image[1])/2):int((len(pr_mask[0])-shape_image[1])/2)+shape_image[1]]\n",
        "\n",
        "    I=len(pr_mask)\n",
        "    J=len(pr_mask[0])\n",
        "    for i in range(I):\n",
        "      for j in range(J):\n",
        "        if all(pr_mask[i,j]==[1,0,0]): # [1,0,0] mean pixel of bubble\n",
        "          pr_mask[i,j]=0\n",
        "        else:\n",
        "          pr_mask[i,j]=255\n",
        "\n",
        "    cv2.imwrite('/content/pr_dir/mask_'+image_names[k][-9:],pr_mask.astype(np.uint8))\n",
        "\n",
        "    #Let compute the IOU score\n",
        "    path=os.path.join(y_test_dir, 'mask'+image_names[k][5:])\n",
        "    gt_mask = cv2.imread(path,0)\n",
        "    pr_mask=np.delete(pr_mask, 0, 2)\n",
        "    pr_mask=np.delete(pr_mask, 0, 2)\n",
        "    pr_mask=np.squeeze(pr_mask)\n",
        "    with tf.Session() as sess:\n",
        "      ypredT = tf.constant(pr_mask/255)\n",
        "      ytrueT = tf.constant(gt_mask/255)\n",
        "      iou,conf_mat = tf.metrics.mean_iou(ytrueT, ypredT, num_classes=3)\n",
        "      sess.run(tf.local_variables_initializer())\n",
        "      sess.run([conf_mat])\n",
        "      miou = sess.run([iou])\n",
        "    average_iou_Unet=average_iou_Unet+miou[0]\n",
        "    #print(miou[0])\n",
        "\n",
        "# Test dataset\n",
        "dataset_test_Unet = ShapesDataset()\n",
        "dataset_test_Unet.load_shapes(x_test_dir, '/content/pr_dir')\n",
        "dataset_test_Unet.prepare()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/metrics_impl.py:1178: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2ugzfFKVn6S",
        "colab_type": "text"
      },
      "source": [
        "We compute the mAP for Unet and print it with the IOU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7bc68d4b-b1dd-456c-8fdd-a586f100c834",
        "id": "JfItOo3Nn6xW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "\n",
        "image_ids =dataset_test.image_ids\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_test, inference_config,\n",
        "                               image_id, use_mini_mask=False)\n",
        "\n",
        "    # Load predicted mask\n",
        "    image, image_meta, pr_class_id, pr_bbox, pr_mask =\\\n",
        "        modellib.load_image_gt(dataset_test_Unet, inference_config,\n",
        "                               image_id, use_mini_mask=False)\n",
        "\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         pr_bbox, pr_class_id, np.ones((len(pr_class_id))), pr_mask)\n",
        "    APs.append(AP)\n",
        "    \n",
        "print('Unet IOU: ', round(average_iou_Unet/n,3)) #Was computed in the previous block\n",
        "print(\"Unet mAP: \", round(np.mean(APs),3))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unet IOU:  0.811\n",
            "Unet mAP:  0.792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrdiYKVuVb-Z",
        "colab_type": "text"
      },
      "source": [
        "We compute the mAP and IOU for Mask RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "74b4dcfd-25b7-4500-ecb8-c4e19abed8ea",
        "id": "6Ai9HGSRoCAV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "\n",
        "image_ids =dataset_test.image_ids\n",
        "APs = []\n",
        "average_iou_Mask_RCNN=0\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_test, inference_config,\n",
        "                               image_id, use_mini_mask=False)\n",
        "    # Run object detection\n",
        "    results = model_Mask_RCNN.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], np.ones((len(r['class_ids']))), r['masks'])\n",
        "    APs.append(AP)\n",
        "\n",
        "    semantic_pr_mask=semantic_mask(r['masks'])\n",
        "    semantic_gt_mask = semantic_mask(gt_mask)\n",
        "    with tf.Session() as sess:\n",
        "      ypredT = tf.constant(semantic_pr_mask)\n",
        "      ytrueT = tf.constant(semantic_gt_mask)\n",
        "      iou,conf_mat = tf.metrics.mean_iou(ytrueT, ypredT, num_classes=3)\n",
        "      sess.run(tf.local_variables_initializer())\n",
        "      sess.run([conf_mat])\n",
        "      miou = sess.run([iou])\n",
        "    average_iou_Mask_RCNN=average_iou_Mask_RCNN+miou[0]\n",
        "    #print(miou)\n",
        "\n",
        "print('Mask RCNN IOU: ', round(average_iou_Mask_RCNN/n,3))  \n",
        "print(\"Mask RCNN mAP: \", round(np.mean(APs),3))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mask RCNN IOU:  0.82\n",
            "Mask RCNN mAP:  0.904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZfdiHsZmBCS",
        "colab_type": "text"
      },
      "source": [
        "Now let compare the time of segmentation of Unet with Mask RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5IEVOWOmYWl",
        "colab_type": "code",
        "outputId": "cb0bfa35-643c-4b00-b4ee-cf0618f665d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tic=time.perf_counter()\n",
        "\n",
        "for k in range(n):\n",
        "    image, shape_image= test_dataset[k]\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    pr_mask = model_Unet.predict(image).round()[0]\n",
        "\n",
        "tac=time.perf_counter()\n",
        "\n",
        "print('In average Unet took '+str(round((tac-tic)/n,2))+'s per image')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In average Unet took 0.05s per image\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ca14b6e2-dfa5-4c6a-dd1a-3feceb393abe",
        "id": "TtjQsPlnpGXX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        }
      },
      "source": [
        "tic=time.perf_counter()\n",
        "\n",
        "for image_name in image_names:\n",
        "  path=os.path.join(x_test_dir, image_name)\n",
        "  image = cv2.imread(path)\n",
        "  results = model_Mask_RCNN.detect([image], verbose=1)\n",
        "\n",
        "tac=time.perf_counter()\n",
        "\n",
        "print('\\n In average Mask RCNN took '+str(round((tac-tic)/n,2))+'s per image')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing 1 images\n",
            "image                    shape: (128, 128, 3)         min:   63.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 512, 512, 3)      min:  -60.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  512.00000  float64\n",
            "anchors                  shape: (1, 65472, 4)         min:   -0.17712  max:    1.05188  float32\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:   34.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 512, 512, 3)      min:  -87.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  512.00000  float64\n",
            "anchors                  shape: (1, 65472, 4)         min:   -0.17712  max:    1.05188  float32\n",
            "Processing 1 images\n",
            "image                    shape: (128, 256, 3)         min:   87.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 512, 1024, 3)     min:  -36.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 130944, 4)        min:   -0.17712  max:    1.05188  float32\n",
            "Processing 1 images\n",
            "image                    shape: (125, 125, 3)         min:   63.00000  max:  242.00000  uint8\n",
            "molded_images            shape: (1, 512, 512, 3)      min:  -60.70000  max:  137.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  512.00000  float64\n",
            "anchors                  shape: (1, 65472, 4)         min:   -0.17712  max:    1.05188  float32\n",
            "Processing 1 images\n",
            "image                    shape: (384, 544, 3)         min:  104.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 512, 768, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  768.00000  float64\n",
            "anchors                  shape: (1, 98208, 4)         min:   -0.17712  max:    1.05188  float32\n",
            "Processing 1 images\n",
            "image                    shape: (128, 128, 3)         min:  113.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 512, 512, 3)      min:  -10.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  512.00000  float64\n",
            "anchors                  shape: (1, 65472, 4)         min:   -0.17712  max:    1.05188  float32\n",
            "Processing 1 images\n",
            "image                    shape: (384, 544, 3)         min:   69.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 512, 768, 3)      min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  768.00000  float64\n",
            "anchors                  shape: (1, 98208, 4)         min:   -0.17712  max:    1.05188  float32\n",
            "Processing 1 images\n",
            "image                    shape: (128, 128, 3)         min:   59.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 512, 512, 3)      min:  -64.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max:  512.00000  float64\n",
            "anchors                  shape: (1, 65472, 4)         min:   -0.17712  max:    1.05188  float32\n",
            "\n",
            " In average Mask RCNN took 0.33s per image\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}